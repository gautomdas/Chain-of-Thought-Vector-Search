{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eebe43f-4656-4f9d-876e-b9f5cf200f09",
   "metadata": {},
   "source": [
    "# End-to-End Query Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "49a174d7-84d5-485c-b2da-174f6ca77554",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Planning\n",
    "# pseudo code for a given query is to\n",
    "# convert a query to triples that can be used to search for it\n",
    "# find key subjects/objects + predicates to query for\n",
    "# upon a given search and return triples, there are two options\n",
    "# use an LLM to \n",
    "# 1. check if there is any answer in the given triples\n",
    "# 2. if there are, return\n",
    "# 3. if not, filter triples that seem completely unrelated\n",
    "# 4. get the return values of the triples, check if any have already been searched\n",
    "# 5. for the ones that haven't loop through again and gather more information\n",
    "# convert to triple\n",
    "# query triple\n",
    "# find top matches and top similar\n",
    "# check for answers -> if found return\n",
    "# otherwise \n",
    "# filter triples to look for more information\n",
    "# query top 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14195095-7d9c-4295-8fc2-900d37cffe64",
   "metadata": {},
   "source": [
    "## Load Question Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f51d6883-8324-49f8-b964-9d8fc7beb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Load JSON data for qa's with answers\n",
    "with open('strategyqa-data/strategyqa_dataset/strategyqa_train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "questions_answers = {}\n",
    "for item in data:\n",
    "    questions_answers[item['question']] = item['answer']\n",
    "    \n",
    "# Load question set from cluster\n",
    "question_set = set()\n",
    "with open('question_clusters/cluster4.json', 'r') as f:\n",
    "    loaded_strings = json.load(f)\n",
    "    \n",
    "for l in loaded_strings:\n",
    "    question_set.add(l)\n",
    "    \n",
    "# Helper Functions\n",
    "def get_query_answer(query):\n",
    "    return questions_answers[query]\n",
    "\n",
    "def get_random_query():\n",
    "    return list(question_set)[random.randint(0, len(question_set))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa0d80c5-cd32-4447-b006-7a7155330ffa",
   "metadata": {},
   "source": [
    "## OpenAI Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "abe52365-e455-4af9-aa5f-6e8d6a1c37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_prompt(text):\n",
    "    multi_line_prompt = \"\"\"\n",
    "There exists a theoretical data store that consists of \"triples\" that come from a paragraph of information that has been deconstructed. A \"triple\" is an information structure that captures specific relationships or connections between two distinct entities. These entities can take various forms such as objects, facts, direct quotes, numbers, or any other meaningful data from the text.  As an example, look at the \"Text\" input below and the \"Output\" that is followed by different triples:\n",
    "\n",
    "Text:\\\"\\\"\\\"John, a software engineer at Google, moved to San Francisco in 2018. He works on the AI research team, which is led by Dr. Sara Thompson.\\\"\\\"\\\"\n",
    "\n",
    "Output:\n",
    "(\"John\", \"is a\", \"software engineer\")\n",
    "(\"John\", \"works at\", \"Google\")\n",
    "(\"John\", \"moved to\", \"San Francisco in 2018\")\n",
    "(\"John\", \"works on\", \"the AI research team\")\n",
    "(\"AI research team\", \"is led by\", \"Dr. Sara Thompson\")\n",
    "\n",
    "Your goal is to take a given question, which comes after \"Question:\" and convert it into a series of triples that can query the triple data store to find information after the phrase \"Output:\". The output triples should have at least one \"_\" (blank character) to denote information to query. For example:\n",
    "\n",
    "Question: \"Where does john work\"\n",
    "Output:\n",
    "(\"John\", \"works at\", _)\n",
    "(\"John\", \"is a\", _)\n",
    "\n",
    "The \"_\" can be anywhere that could be used as a query. For example,\n",
    "\n",
    "Question: \"What does John do at Google?\"\n",
    "Output:\n",
    "(\"John\", _, \"Google\")\n",
    "\n",
    "The goal, is to return as many triples would be useful to query information needed. Sometimes questions, will be \"Multi-hop\" meaning they require multiple pieces of information to query. When a question appears to be more complex, break down the question so that there are multiple queries that can be used to get information. Additionally, each query will return more triples that can be used to before a linked search towards information. Now convert the following question:\n",
    "\n",
    "Question: \"{}\"\n",
    "Output:\n",
    "    \"\"\".format(text)\n",
    "    return multi_line_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e01b8373-dc6a-42e0-95d2-d7bc18c6b379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_response(multi_line_prompt):\n",
    "    openai.api_key = \"<KEY>\"\n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=multi_line_prompt,\n",
    "      max_tokens=300\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def get_chat_response(multi_line_prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an experiment information retrieval and query processing machine.\"},\n",
    "            {\"role\": \"user\", \"content\": multi_line_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "704beba6-52f9-476f-b2bc-3503db6649d6",
   "metadata": {},
   "source": [
    "### Query and Query Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fd3d4343-409f-42a1-bff5-6bf0e3a90856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Query: Would a northern fur seal pass a driving test?\n",
      "Answer: False\n"
     ]
    }
   ],
   "source": [
    "backup_query = \"Can Clouded leopards chase down many Pronghorn antelopes?\"\n",
    "query = get_random_query()\n",
    "print(\"Starting Query: {}\".format(query))\n",
    "print(\"Answer: {}\".format(get_query_answer(query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b1b4587b-6de6-407f-b72a-9ce64b923319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(\"Northern fur seal\", _, _)\n",
      "(_, \"pass a\", \"driving test\")\n"
     ]
    }
   ],
   "source": [
    "response = get_response(get_question_prompt(query))\n",
    "# GPT 3.5 response print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "# davinci-003 print(get_response[\"choices\"][0][\"text\"])\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "94a1af89-2df2-4503-8723-35873fe127d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from qdrant_client.http import models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "qdrant_client = QdrantClient('http://localhost:6333')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3c728e85-6dd1-46c2-b061-f255d268281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_triple_from_string_to_array(trip):\n",
    "    return [val[1:-1] for val in trip.strip()[1:-1].split(\", \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4e2418da-7a97-4342-a822-b9a0a38f35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_subjects(search_text):\n",
    "    encoded_search = model.encode(search_text)\n",
    "    search_result = qdrant_client.search(\n",
    "            collection_name=\"subjects\",\n",
    "            query_vector=encoded_search.tolist(),\n",
    "            query_filter=None,  # If you don't want any filters for now\n",
    "            limit=5  # 5 the most closest results is enough\n",
    "        )\n",
    "    return search_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4baddd-19a8-47ea-9c6d-5c336dc7d33a",
   "metadata": {},
   "source": [
    "## Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f1505457-02ed-41e0-aaf9-4ada634c6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_algorithm(query, steps=5):\n",
    "    all_triples = set([])\n",
    "    response = get_response(get_question_prompt(query))\n",
    "    query_triples = [process_triple_from_string_to_array(trip) for trip in response[\"choices\"][0][\"text\"].strip().split(\"\\n\")]\n",
    "    \n",
    "    query_subject_array = []\n",
    "    for trip in query_triples:\n",
    "        if len(trip)>2:\n",
    "            if not (trip[0] == \"\" or trip[0] == \"\"):\n",
    "                query_subject_array.append(trip[0])\n",
    "            if not (trip[2] == \"\" or trip[2] == \"\"):\n",
    "                query_subject_array.append(trip[2])\n",
    "            \n",
    "    query_subject_set = set(query_subject_array)\n",
    "    \n",
    "    for i in range(0, steps-1):\n",
    "        # print(\"Starting Subject Set:\", query_subject_set)\n",
    "        query_subject_array = []\n",
    "        for subject in query_subject_set:\n",
    "            query_response = query_subjects(subject)\n",
    "            returned_triples = [process_triple_from_string_to_array(match.payload[\"triple\"]) for match in query_response]\n",
    "            \n",
    "            # all_triples += returned_triples\n",
    "            for trip in returned_triples:\n",
    "                to_add = \", \".join([\"\\\"\"+t+\"\\\"\" for t in trip])\n",
    "                all_triples.add(\"(\"+to_add+\")\")\n",
    "                \n",
    "            # print(\"New Triples:\", returned_triples)\n",
    "            \n",
    "            for trip in returned_triples: \n",
    "                if (len(trip) > 2):\n",
    "                    query_subject_array.append(trip[0])\n",
    "                    query_subject_array.append(trip[2])\n",
    "            \n",
    "        query_subject_set = set(query_subject_array)\n",
    "        \n",
    "    return all_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7e61d3ac-8cc3-4306-874e-7d6c54b114fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triples = query_algorithm(query, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62d50b98-f36c-495a-8483-e2665b495c56",
   "metadata": {},
   "source": [
    "## Relevant Informational Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "616b3d08-e95d-4b7b-aea5-18c1a4ab6a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"northern fur seal\", \"found in\", \"Sea of Okhotsk\")\n",
      "(\"northern fur seal\", \"some breed on\", \"Tyuleniy Island off the coast of Sakhalin in the southwest Sea of Okhotsk\")\n",
      "(\"driving test\", \"consists of\", \"written or oral test (theory test)\")\n",
      "(\"northern fur seal\", \"found in\", \"Bering Sea\")\n",
      "(\"northern fur seal\", \"is the largest member of\", \"fur seal subfamily\")\n",
      "(\"driving test\", \"is a procedure\", \"designed to test a person's ability to drive a motor vehicle\")\n",
      "(\"northern fur seal\", \"is the only living species in\", \"genus Callorhinus\")\n",
      "(\"driving test\", \"is often a requirement to\", \"obtain a driver's license\")\n",
      "(\"driving test\", \"exists in\", \"various forms worldwide\")\n",
      "(\"driving test\", \"is used to\", \"assess a person's driving ability under normal operating conditions\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def triples_to_string(all_triples):\n",
    "    triples_as_strings = \"\"\n",
    "    for trip in all_triples:\n",
    "        triples_as_strings += trip+\"\\n\"\n",
    "    return triples_as_strings\n",
    "\n",
    "triples_as_strings = triples_to_string(all_triples)\n",
    "print(triples_as_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "46a7d43e-3389-407d-9f7a-7228c65f3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_prompt(triples, query):\n",
    "    multi_line_prompt = \"\"\"\n",
    "A \"triple\" is an information structure that captures specific relationships or connections between two distinct entities. These entities can take various forms such as objects, facts, direct quotes, numbers, or any other meaningful data from the text.  As an example, look at the \"Text\" input below and the \"Output\" that is followed by different triples:\n",
    "\n",
    "Text:\\\"\\\"\\\"John, a software engineer at Google, moved to San Francisco in 2018. He works on the AI research team, which is led by Dr. Sara Thompson.\\\"\\\"\\\"\n",
    "\n",
    "Output:\n",
    "(\"John\", \"is a\", \"software engineer\")\n",
    "(\"John\", \"works at\", \"Google\")\n",
    "(\"John\", \"moved to\", \"San Francisco in 2018\")\n",
    "(\"John\", \"works on\", \"the AI research team\")\n",
    "(\"AI research team\", \"is led by\", \"Dr. Sara Thompson\")\n",
    "\n",
    "Your goal is to take a given set of triples and answer a query about them. Your goal is to take a given set of triples and answer a query about them. To do this, look at all the information present in the triples and try to come up with the most rational answer based on the connections that exist with the triples. Every answer is equally likely to be true or false. The triples will be provided after \"Triples\", the query will be provided after \"Query\", and the answer which you will write should be provided after \"Answer\". An Answer should always be a boolean either true or false. The answer response should always only be \"true\" or \"false\" you shouldn't say anything more. For example,\n",
    "\n",
    "Triples:\n",
    "(\"John\", \"works on\", \"the AI research team\")\n",
    "(\"AI research team\", \"is led by\", \"Dr. Sara Thompson\")\n",
    "\n",
    "Query: \"Does John work with Sara Thompson\"\n",
    "Answer: true\n",
    "\n",
    "Now try for the following triples and query to provide either a true or false answer:\n",
    "\n",
    "Triples:\n",
    "{}\n",
    "\n",
    "Query: \"{}\"\n",
    "Answer:\n",
    "    \"\"\".format(triples, query)\n",
    "    return multi_line_prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6555531-90c4-4e98-8576-f755dedcd22e",
   "metadata": {},
   "source": [
    "## Test Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "dbefd42e-2a7e-4274-a45b-2223c0d91987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    attempted_answer = get_response(get_answer_prompt(triples_as_strings, query))[\"choices\"][0][\"text\"]\n",
    "    answer = string_to_bool(attempted_answer.lower().strip())\n",
    "    if answer==\"fail\":\n",
    "        # failed_answers+= 1\n",
    "        print(\"- Model Failed to Answer. Attempted: {}\".format(attempted_answer.lower().strip()))\n",
    "    else:\n",
    "        print(\"Model Answer: {}\".format(answer))\n",
    "        correct_answer = get_query_answer(query)\n",
    "        print(\"Correct Answer: {}\".format(correct_answer))\n",
    "        if correct_answer==answer:\n",
    "            print(\"+ Model Answered Correct !\")\n",
    "            #correct_answers += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "eadcb3e7-5867-48f4-8f62-43bb222c02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT 3.5 Turbo Response\n",
    "## get_chat_response(get_answer_prompt(triples_as_strings, query))[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e63c1ae6-1b05-4fc9-815a-f2f5452ca466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "53cfcea8-cffa-49d0-87c1-a9d9084ab160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_bool(string):\n",
    "    if string==\"true\":\n",
    "        return True\n",
    "    elif string==\"false\":\n",
    "        return False\n",
    "    else:\n",
    "        return \"fail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d5e82df5-e8a2-45e0-8c30-f89e4293c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query_full(query):\n",
    "    #failed_answers = 0\n",
    "    #correct_answers = 0\n",
    "\n",
    "    all_triples = query_algorithm(query, 3)\n",
    "    triples_as_strings = triples_to_string(all_triples)\n",
    "    attempted_answer = get_response(get_answer_prompt(triples_as_strings, query))[\"choices\"][0][\"text\"]\n",
    "    answer = string_to_bool(attempted_answer.lower().strip())\n",
    "    print(\"Query: {}\".format(query))\n",
    "    \n",
    "    if answer==\"fail\":\n",
    "        # failed_answers+= 1\n",
    "        print(\"- Model Failed to Answer. Attempted: {}\".format(attempted_answer.lower().strip()))\n",
    "    else:\n",
    "        print(\"Model Answer: {}\".format(answer))\n",
    "        correct_answer = get_query_answer(query)\n",
    "        print(\"Correct Answer: {}\".format(correct_answer))\n",
    "        if correct_answer==answer:\n",
    "            print(\"+ Model Answered Correct !\")\n",
    "            #correct_answers += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "af18ef90-4647-47e6-8028-ae168c0b4c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Have rhinoceroses been killed to improve human sex lives?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Is the Golden eagle considered a scavenger bird?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Is a jellyfish safe from atherosclerosis?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Would a diet of ice eventually kill a person?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Do manta rays live in water above the safe temperature for cold food storage?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Are aggressive bumblebees suicidal?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Would WWF be angrier if you killed koala instead of black swan?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Is Bactrian Camel most impressive animal when it comes to number of humps?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Has Gorillaz creator been in more bands than Bernard Sumner?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Do giraffes require special facilities at zoos?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Would a German Shepherd be welcome in an airport?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Are moose used for work near the kingdom of Arendelle?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Can crane slamdunk?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Is a Cassowary safer pet than a crane?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Is a cory catfish likely to eat another living fish?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Did occupants of Vellore Fort need to defend themselves from Grizzly Bears?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Are chinchillas cold-blooded?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Do storks need golden toads to survive?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Would hypothermia be a concern for a human wearing zoot suit on Triton?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Do sand cats avoid eating all of the prey of eels?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Would a Bengal cat be afraid of catching a fish?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Does it seem like the Gorillaz is composed of more members than they have?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Would a northern fur seal pass a driving test?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Would it be wise to bring a robusto into Central Park Zoo?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Could two newborn American Black Bear cubs fit on a king size bed?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Would a nickel fit inside a koala pouch?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Does Pikachu like Charles Darwin?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Can a sniper shoot a fish past Bathypelagic Zone in ocean?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n",
      "Query: Would Constitution of the United States paper offend PETA?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Was animal in You're a Good Sport, Charlie Brown, hypothetically a hound?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Are there any chives hypothetically good for battling vampires?\n",
      "Model Answer: False\n",
      "Correct Answer: True\n",
      "None\n",
      "Query: Are Sable's a good choice of Mustelidae to weigh down a scale?\n",
      "Model Answer: False\n",
      "Correct Answer: False\n",
      "+ Model Answered Correct !\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [199]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m question_set:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_query_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [198]\u001b[0m, in \u001b[0;36mtest_query_full\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_query_full\u001b[39m(query):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#failed_answers = 0\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#correct_answers = 0\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     all_triples \u001b[38;5;241m=\u001b[39m \u001b[43mquery_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     triples_as_strings \u001b[38;5;241m=\u001b[39m triples_to_string(all_triples)\n\u001b[1;32m      7\u001b[0m     attempted_answer \u001b[38;5;241m=\u001b[39m get_response(get_answer_prompt(triples_as_strings, query))[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Input \u001b[0;32mIn [174]\u001b[0m, in \u001b[0;36mquery_algorithm\u001b[0;34m(query, steps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_algorithm\u001b[39m(query, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      2\u001b[0m     all_triples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([])\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_question_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     query_triples \u001b[38;5;241m=\u001b[39m [process_triple_from_string_to_array(trip) \u001b[38;5;28;01mfor\u001b[39;00m trip \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      6\u001b[0m     query_subject_array \u001b[38;5;241m=\u001b[39m []\n",
      "Input \u001b[0;32mIn [124]\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(multi_line_prompt)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_response\u001b[39m(multi_line_prompt):\n\u001b[1;32m      4\u001b[0m     openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-8vHIuaM3PAQAbgk8eUr3T3BlbkFJkP3sTwy1JQJDcbv5yehH\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_line_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for q in question_set:\n",
    "    print(test_query_full(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb980fe-6da3-4c4f-b617-0a7117fa4508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
